# activation.py
import torch
import torch.nn as nn

class SymbolicActivation(nn.Module):
    def __init__(self, alpha=1.0):
        super().__init__()
        self.alpha = alpha

    def forward(self, x):
        # Example: entropy-aware sigmoid variant
        return x * torch.sigmoid(self.alpha * x)  # Swish-like but tunable

# Example usage in a model
class SimpleNet(nn.Module):
    def __init__(self, activation_fn):
        super().__init__()
        self.fc1 = nn.Linear(784, 128)
        self.act1 = activation_fn
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = x.view(-1, 784)
        x = self.act1(self.fc1(x))
        return self.fc2(x)
